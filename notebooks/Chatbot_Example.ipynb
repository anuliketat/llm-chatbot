{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43a400ae8bdc45f3a33a0c1464154f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_147d2d4b46404f2aa15eee266e672e21",
            "placeholder": "Type your message here...",
            "style": "IPY_MODEL_97850a955eaa4a39ab569f5b4005cc74",
            "value": ""
          }
        },
        "147d2d4b46404f2aa15eee266e672e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97850a955eaa4a39ab569f5b4005cc74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c3f277df0943a2af93a1798de583b1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4a2a12a883584fc5ada7f6b675159b7c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: h\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Bot: Hello! How can I assist you today?\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: i lost my gift ca\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Bot: I'm sorry to hear that you lost your gift card. To help you further, could you please provide more details such as where you purchased the gift card, the approximate date of purchase, and any other relevant information that could assist in locating or replacing it?\n"
                ]
              }
            ]
          }
        },
        "4a2a12a883584fc5ada7f6b675159b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkDmGnUKudFf",
        "outputId": "1a958a27-1a18-4293-b4e0-f00f2eadaeae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "43a400ae8bdc45f3a33a0c1464154f8f",
            "147d2d4b46404f2aa15eee266e672e21",
            "97850a955eaa4a39ab569f5b4005cc74",
            "61c3f277df0943a2af93a1798de583b1",
            "4a2a12a883584fc5ada7f6b675159b7c"
          ]
        },
        "id": "JTeW8HZQuF6t",
        "outputId": "61a845a7-ad56-4d03-c86c-91675a444622"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='You:', placeholder='Type your message here...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43a400ae8bdc45f3a33a0c1464154f8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c3f277df0943a2af93a1798de583b1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import userdata as ud\n",
        "\n",
        "API_KEY = ud.get('fine_tuned_model_chatbot')\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "prompt = '''You are a friendly and accurate customer support assistant for Our company. Provide specific answers based on the user’s query while maintaining a conversational and engaging tone.\n",
        "            Always ask for necessary details like product name, SKU, serial number, email, etc., if needed.\n",
        "            If you are unsure about any information, ask for clarification or confirmation from the user rather than providing potentially inaccurate information.\n",
        "            Your goal is to help the customer with the exact information they need while keeping the conversation flowing naturally.'''\n",
        "\n",
        "conversation_history = [{\"role\": \"system\", \"content\": prompt}]\n",
        "\n",
        "few_shot_examples = [\n",
        "              {\"role\": \"user\", \"content\": \"Can I get a replacement part for my product?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Certainly! Can you please provide the product name, SKU, or serial number, and a description of the part you need?\"},\n",
        "              {\"role\": \"user\", \"content\": \"How can I reset my product?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Sure! To assist you with resetting your product, could you please provide the product name and model number?\"}\n",
        "          ]\n",
        "conversation_history.extend(few_shot_examples)\n",
        "\n",
        "def get_gpt3_response(prompt):\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "    fine_tuned_model = \"ft:gpt-3.5-turbo-0125:personal::9cINtknt\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=fine_tuned_model,\n",
        "        messages=conversation_history,\n",
        "        temperature=0.3,\n",
        "        # seed=123\n",
        "        # max_tokens=80,\n",
        "        # top_p=0.2,\n",
        "        # frequency_penalty=0.5,\n",
        "        # presence_penalty=0.6\n",
        "    )\n",
        "    reply = response.choices[0].message.content\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return reply\n",
        "\n",
        "# input box widget\n",
        "input_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Type your message here...',\n",
        "    description='You:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# output widget\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle user input and display response\n",
        "def on_submit(change):\n",
        "    user_input = input_box.value\n",
        "    with output:\n",
        "        # clear_output(wait=True)\n",
        "        print(f\"You: {user_input}\")\n",
        "        response = get_gpt3_response(user_input)\n",
        "        print(f\"Bot: {response}\")\n",
        "    input_box.value = ''\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box, output)"
      ]
    }
  ]
}